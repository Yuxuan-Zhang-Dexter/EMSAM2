{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAM Video Segmentation Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Global Variables\n",
    "\n",
    "CHECKPOINT = \"./sam2_hiera_large.pt\"\n",
    "CONFIG = \"sam2_hiera_l.yaml\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
    "\n",
    "sam2_model = build_sam2_video_predictor(CONFIG, CHECKPOINT, device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Utils Function\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import dateutil.tz\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "\n",
    "def set_log_dir(root_dir, exp_name):\n",
    "    path_dict = {}\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "\n",
    "    # set log path\n",
    "    exp_path = os.path.join(root_dir, exp_name)\n",
    "    now = datetime.now(dateutil.tz.tzlocal())\n",
    "    timestamp = now.strftime('%Y_%m_%d_%H_%M_%S')\n",
    "    prefix = exp_path + '_' + timestamp\n",
    "    os.makedirs(prefix)\n",
    "    path_dict['prefix'] = prefix\n",
    "\n",
    "    # set checkpoint path\n",
    "    ckpt_path = os.path.join(prefix, 'Model')\n",
    "    os.makedirs(ckpt_path)\n",
    "    path_dict['ckpt_path'] = ckpt_path\n",
    "\n",
    "    log_path = os.path.join(prefix, 'Log')\n",
    "    os.makedirs(log_path)\n",
    "    path_dict['log_path'] = log_path\n",
    "\n",
    "    # set sample image path for fid calculation\n",
    "    sample_path = os.path.join(prefix, 'Samples')\n",
    "    os.makedirs(sample_path)\n",
    "    path_dict['sample_path'] = sample_path\n",
    "\n",
    "    return path_dict\n",
    "\n",
    "\n",
    "\n",
    "def create_logger(log_dir, phase='train'):\n",
    "    time_str = time.strftime('%Y-%m-%d-%H-%M')\n",
    "    log_file = '{}_{}.log'.format(time_str, phase)\n",
    "    final_log_file = os.path.join(log_dir, log_file)\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(filename=str(final_log_file),\n",
    "                        format=head)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    console = logging.StreamHandler()\n",
    "    logging.getLogger('').addHandler(console)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAM2VideoPredictor(\n",
       "  (image_encoder): ImageEncoder(\n",
       "    (trunk): Hiera(\n",
       "      (patch_embed): PatchEmbed(\n",
       "        (proj): Conv2d(3, 144, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "      )\n",
       "      (blocks): ModuleList(\n",
       "        (0-1): 2 x MultiScaleBlock(\n",
       "          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=144, out_features=432, bias=True)\n",
       "            (proj): Linear(in_features=144, out_features=144, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=144, out_features=576, bias=True)\n",
       "              (1): Linear(in_features=576, out_features=144, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "        (2): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((144,), eps=1e-06, elementwise_affine=True)\n",
       "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "            (qkv): Linear(in_features=144, out_features=864, bias=True)\n",
       "            (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "              (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "          (proj): Linear(in_features=144, out_features=288, bias=True)\n",
       "        )\n",
       "        (3-7): 5 x MultiScaleBlock(\n",
       "          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=288, out_features=864, bias=True)\n",
       "            (proj): Linear(in_features=288, out_features=288, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=288, out_features=1152, bias=True)\n",
       "              (1): Linear(in_features=1152, out_features=288, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "        (8): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((288,), eps=1e-06, elementwise_affine=True)\n",
       "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "            (qkv): Linear(in_features=288, out_features=1728, bias=True)\n",
       "            (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "              (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "          (proj): Linear(in_features=288, out_features=576, bias=True)\n",
       "        )\n",
       "        (9-43): 35 x MultiScaleBlock(\n",
       "          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=576, out_features=1728, bias=True)\n",
       "            (proj): Linear(in_features=576, out_features=576, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=576, out_features=2304, bias=True)\n",
       "              (1): Linear(in_features=2304, out_features=576, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "        (44): MultiScaleBlock(\n",
       "          (norm1): LayerNorm((576,), eps=1e-06, elementwise_affine=True)\n",
       "          (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (q_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "            (qkv): Linear(in_features=576, out_features=3456, bias=True)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "              (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "          (proj): Linear(in_features=576, out_features=1152, bias=True)\n",
       "        )\n",
       "        (45-47): 3 x MultiScaleBlock(\n",
       "          (norm1): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): MultiScaleAttention(\n",
       "            (qkv): Linear(in_features=1152, out_features=3456, bias=True)\n",
       "            (proj): Linear(in_features=1152, out_features=1152, bias=True)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((1152,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=1152, out_features=4608, bias=True)\n",
       "              (1): Linear(in_features=4608, out_features=1152, bias=True)\n",
       "            )\n",
       "            (act): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): FpnNeck(\n",
       "      (position_encoding): PositionEmbeddingSine()\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (conv): Conv2d(1152, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (conv): Conv2d(576, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (conv): Conv2d(144, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mask_downsample): Conv2d(1, 1, kernel_size=(4, 4), stride=(4, 4))\n",
       "  (memory_attention): MemoryAttention(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x MemoryAttentionLayer(\n",
       "        (self_attn): RoPEAttention(\n",
       "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (cross_attn_image): RoPEAttention(\n",
       "          (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (k_proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (v_proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (memory_encoder): MemoryEncoder(\n",
       "    (mask_downsampler): MaskDownSampler(\n",
       "      (encoder): Sequential(\n",
       "        (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (1): LayerNorm2d()\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Conv2d(4, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (4): LayerNorm2d()\n",
       "        (5): GELU(approximate='none')\n",
       "        (6): Conv2d(16, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (7): LayerNorm2d()\n",
       "        (8): GELU(approximate='none')\n",
       "        (9): Conv2d(64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        (10): LayerNorm2d()\n",
       "        (11): GELU(approximate='none')\n",
       "        (12): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (pix_feat_proj): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (fuser): Fuser(\n",
       "      (proj): Identity()\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x CXBlock(\n",
       "          (dwconv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (norm): LayerNorm2d()\n",
       "          (pwconv1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (pwconv2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (drop_path): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position_encoding): PositionEmbeddingSine()\n",
       "    (out_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (sam_prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       "  (sam_mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (layers): ModuleList(\n",
       "              (0): Linear(in_features=256, out_features=2048, bias=True)\n",
       "              (1): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            )\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (obj_score_token): Embedding(1, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (conv_s0): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv_s1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "        (act): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "      (act): ReLU()\n",
       "    )\n",
       "    (pred_obj_score_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=1, bias=True)\n",
       "      )\n",
       "      (act): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (obj_ptr_proj): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (act): ReLU()\n",
       "  )\n",
       "  (obj_ptr_tpos_proj): Identity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Print Out Sam2 Model Architecutre\n",
    "sam2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Load Layer Parameters\n",
    "sam_layers = ([]\n",
    "            # + list(sam2_model.image_encoder.parameters())\n",
    "            + list(sam2_model.sam_prompt_encoder.parameters())\n",
    "            + list(sam2_model.sam_mask_decoder.parameters())\n",
    "            )\n",
    "mem_layers = ([]\n",
    "            + list(sam2_model.obj_ptr_proj.parameters())\n",
    "            + list(sam2_model.memory_encoder.parameters())\n",
    "            + list(sam2_model.memory_attention.parameters())\n",
    "            + list(sam2_model.mask_downsample.parameters())\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Define Optimizers\n",
    "if len(sam_layers) == 0:\n",
    "    optimizer1 = None\n",
    "else:\n",
    "    optimizer1 = optim.Adam(sam_layers, lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "if len(mem_layers) == 0:\n",
    "    optimizer2 = None\n",
    "else:\n",
    "    optimizer2 = optim.Adam(mem_layers, lr=1e-8, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Float Quantization\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yuxuan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
